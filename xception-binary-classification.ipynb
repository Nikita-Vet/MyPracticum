{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6924300,"sourceType":"datasetVersion","datasetId":3975899}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# download libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.data import Dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:44:56.299844Z","iopub.execute_input":"2023-11-25T10:44:56.300233Z","iopub.status.idle":"2023-11-25T10:45:00.240371Z","shell.execute_reply.started":"2023-11-25T10:44:56.300197Z","shell.execute_reply":"2023-11-25T10:45:00.238360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Download data and visualisation","metadata":{}},{"cell_type":"code","source":"# path to the data\n\nhole_path = \"/kaggle/input/images-of-galaxies-and-black-holes/BlackHole/BlackHole\"\ngalaxy_path = \"/kaggle/input/images-of-galaxies-and-black-holes/Galaxy/Galaxy\"","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.242093Z","iopub.execute_input":"2023-11-25T10:45:00.242875Z","iopub.status.idle":"2023-11-25T10:45:00.250523Z","shell.execute_reply.started":"2023-11-25T10:45:00.242835Z","shell.execute_reply":"2023-11-25T10:45:00.247670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function which gives the list of files names in mentioned folder\n\ndef get_jpg_filenames(folder_path):\n    jpg_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".jpg\")]\n    return jpg_files","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.252673Z","iopub.execute_input":"2023-11-25T10:45:00.253229Z","iopub.status.idle":"2023-11-25T10:45:00.270923Z","shell.execute_reply.started":"2023-11-25T10:45:00.253188Z","shell.execute_reply":"2023-11-25T10:45:00.269509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hole_files = get_jpg_filenames(hole_path)\n\ngalaxy_files = get_jpg_filenames(galaxy_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.273833Z","iopub.execute_input":"2023-11-25T10:45:00.274243Z","iopub.status.idle":"2023-11-25T10:45:00.309880Z","shell.execute_reply.started":"2023-11-25T10:45:00.274201Z","shell.execute_reply":"2023-11-25T10:45:00.308614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hole_lables = [0] * len(hole_files)\n\ngalaxy_lables = [1] * len(galaxy_files)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.311213Z","iopub.execute_input":"2023-11-25T10:45:00.311677Z","iopub.status.idle":"2023-11-25T10:45:00.317954Z","shell.execute_reply.started":"2023-11-25T10:45:00.311644Z","shell.execute_reply":"2023-11-25T10:45:00.316383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframes with names of files and its labeles\n\ndf_hole = pd.DataFrame({\"file_name\": hole_files, \"label\": hole_lables})","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.319220Z","iopub.execute_input":"2023-11-25T10:45:00.319598Z","iopub.status.idle":"2023-11-25T10:45:00.333806Z","shell.execute_reply.started":"2023-11-25T10:45:00.319566Z","shell.execute_reply":"2023-11-25T10:45:00.331998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_galaxy = pd.DataFrame({\"file_name\": galaxy_files, \"label\": galaxy_lables})","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.335674Z","iopub.execute_input":"2023-11-25T10:45:00.336035Z","iopub.status.idle":"2023-11-25T10:45:00.349535Z","shell.execute_reply.started":"2023-11-25T10:45:00.336004Z","shell.execute_reply":"2023-11-25T10:45:00.348367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df_hole, df_galaxy], ignore_index=True)\n\n# For the binary classification labels should be string type\n\ndf['label'] = df['label'].astype(str)\n\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.351205Z","iopub.execute_input":"2023-11-25T10:45:00.351649Z","iopub.status.idle":"2023-11-25T10:45:00.376159Z","shell.execute_reply.started":"2023-11-25T10:45:00.351610Z","shell.execute_reply":"2023-11-25T10:45:00.374544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Verification of class distribution ","metadata":{}},{"cell_type":"code","source":"df['label'].hist(bins=5, figsize=(6, 3))\n\n# Axies\nplt.xlabel('Classies')\nplt.ylabel('Entries')\nplt.title('Class distribution')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.377530Z","iopub.execute_input":"2023-11-25T10:45:00.377892Z","iopub.status.idle":"2023-11-25T10:45:00.559869Z","shell.execute_reply.started":"2023-11-25T10:45:00.377861Z","shell.execute_reply":"2023-11-25T10:45:00.558041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Creating of training and tests dataset ","metadata":{}},{"cell_type":"code","source":"# Split into training and testing sets\n\ntrain_files, test_files, train_labels, test_labels = train_test_split(\n    df['file_name'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.561866Z","iopub.execute_input":"2023-11-25T10:45:00.562394Z","iopub.status.idle":"2023-11-25T10:45:00.571681Z","shell.execute_reply.started":"2023-11-25T10:45:00.562357Z","shell.execute_reply":"2023-11-25T10:45:00.570465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame({\"file_name\": train_files, \"label\": train_labels})\n\ndf_train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.572921Z","iopub.execute_input":"2023-11-25T10:45:00.573224Z","iopub.status.idle":"2023-11-25T10:45:00.591053Z","shell.execute_reply.started":"2023-11-25T10:45:00.573197Z","shell.execute_reply":"2023-11-25T10:45:00.589234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.DataFrame({\"file_name\": test_files, \"label\": test_labels})\n\ndf_test.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.593187Z","iopub.execute_input":"2023-11-25T10:45:00.593693Z","iopub.status.idle":"2023-11-25T10:45:00.607454Z","shell.execute_reply.started":"2023-11-25T10:45:00.593649Z","shell.execute_reply":"2023-11-25T10:45:00.606280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Image generator","metadata":{}},{"cell_type":"code","source":"# Create an image generator for training with data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n# Create training and testing generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=\"file_name/kaggle/input/images-of-galaxies-and-black-holes\",  # root derictory\n    x_col=\"file_name\",  # column with file names\n    y_col=\"label\",  # column with lables\n    target_size=(244, 244),\n    batch_size=32,\n    class_mode=\"binary\",  # mode of classification\n    seed=42,\n    subset='training'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.610997Z","iopub.execute_input":"2023-11-25T10:45:00.611350Z","iopub.status.idle":"2023-11-25T10:45:00.794189Z","shell.execute_reply.started":"2023-11-25T10:45:00.611318Z","shell.execute_reply":"2023-11-25T10:45:00.793277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an image generator for testing (without data augmentation)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=\"file_name/kaggle/input/images-of-galaxies-and-black-holes\",  # root derictory\n    x_col=\"file_name\",  # column with file names\n    y_col=\"label\",  # column with lables\n    target_size=(244, 244),\n    batch_size=32,\n    class_mode=\"binary\",  # mode of classification\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.795166Z","iopub.execute_input":"2023-11-25T10:45:00.795529Z","iopub.status.idle":"2023-11-25T10:45:00.858922Z","shell.execute_reply.started":"2023-11-25T10:45:00.795499Z","shell.execute_reply":"2023-11-25T10:45:00.857916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Visualisation of datasets","metadata":{}},{"cell_type":"code","source":"# visualisation of datasets\nfeatures, target = next(train_generator)\n\n# plot 32 images\nfig = plt.figure(figsize=(12,12))\nfor i in range(32):\n    fig.add_subplot(4, 8, i+1)\n    plt.imshow(features[i])\n    plt.title(f'{target[i]}')\n\t# remove axies\n    plt.xticks([])\n    plt.yticks([])\n    plt.suptitle('Images with labels',  y=0.9,fontsize=16, color='b')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:00.861375Z","iopub.execute_input":"2023-11-25T10:45:00.862169Z","iopub.status.idle":"2023-11-25T10:45:06.668347Z","shell.execute_reply.started":"2023-11-25T10:45:00.862125Z","shell.execute_reply":"2023-11-25T10:45:06.666709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model creation","metadata":{}},{"cell_type":"markdown","source":"Сode below creates an instance of the Xception model, which is a deep convolutional neural network architecture designed for image classification. Here's a breakdown of the parameters:\n\nweights='imagenet': This specifies that you want to load pre-trained weights from the ImageNet dataset. ImageNet is a large dataset with millions of labeled images used for training deep neural networks.\n\ninput_shape=(244, 244, 3): This sets the expected shape of input images that the model will process. In this case, it expects images with a height and width of 180 pixels and three color channels (RGB).\n\ninclude_top=False: This parameter specifies that you do not want to include the top layers of the model. The top layers usually consist of densely connected layers responsible for classifying objects into specific classes based on the ImageNet labels. By setting include_top to False, you are excluding these classification layers, which is often done when you want to use the model for feature extraction or as part of a custom neural network.\n\nIn summary, this code creates the base of the Xception model with pre-trained weights, configured to accept input images of size (244, 244, 3), and without the final classification layers. You can then add your own layers on top of this base model to adapt it to your specific task, like fine-tuning it for a different classification problem or using it for feature extraction.","metadata":{}},{"cell_type":"code","source":"base_model = keras.applications.Xception(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(244, 244, 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top.","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:06.669758Z","iopub.execute_input":"2023-11-25T10:45:06.670130Z","iopub.status.idle":"2023-11-25T10:45:08.433359Z","shell.execute_reply.started":"2023-11-25T10:45:06.670095Z","shell.execute_reply":"2023-11-25T10:45:08.431862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:08.435712Z","iopub.execute_input":"2023-11-25T10:45:08.436307Z","iopub.status.idle":"2023-11-25T10:45:08.448215Z","shell.execute_reply.started":"2023-11-25T10:45:08.436260Z","shell.execute_reply":"2023-11-25T10:45:08.446170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"inputs = keras.Input(shape=(244, 244, 3)): This line defines the input layer of your model. It specifies that your model will expect input images of shape (244, 244, 3), where 244 is the height and width, and 3 is the number of color channels (RGB).\n\nx = base_model(inputs): This line connects the previously defined base_model (Xception in this case) to the input layer. It effectively sets up a pipeline where the input images will be processed by the pre-trained Xception model.\n\nx = keras.layers.GlobalAveragePooling2D()(x): After passing through the base model, the features are processed by a Global Average Pooling 2D layer. This layer computes the average value of each feature map in the spatial dimensions, resulting in a fixed-size vector regardless of the input size. This is often used to reduce the spatial dimensions and flatten the features before passing them to the final classification layers.\n\noutputs = keras.layers.Dense(1, activation='sigmoid')(x): This line adds a Dense layer with a single unit and a sigmoid activation function. This is the final layer responsible for binary classification. The output is a single value between 0 and 1, representing the probability of the input image belonging to the positive class (e.g., in binary classification, 1 represents the positive class).\n\nmodel = keras.Model(inputs, outputs): Finally, this line creates the overall model by specifying the inputs and outputs. This is a common way to define a model in Keras using the Functional API. The resulting model can be trained using appropriate data and optimization techniques.\n\nIn summary, this code constructs a neural network model for binary classification using a pre-trained Xception base model. The Global Average Pooling layer is used to reduce spatial dimensions, and a Dense layer with a sigmoid activation function produces the final classification output.","metadata":{}},{"cell_type":"code","source":"inputs = keras.Input(shape=(244, 244, 3))\nx = base_model(inputs)\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:08.450679Z","iopub.execute_input":"2023-11-25T10:45:08.451144Z","iopub.status.idle":"2023-11-25T10:45:08.911962Z","shell.execute_reply.started":"2023-11-25T10:45:08.451110Z","shell.execute_reply":"2023-11-25T10:45:08.910334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:08.913562Z","iopub.execute_input":"2023-11-25T10:45:08.913868Z","iopub.status.idle":"2023-11-25T10:45:08.953284Z","shell.execute_reply.started":"2023-11-25T10:45:08.913841Z","shell.execute_reply":"2023-11-25T10:45:08.952245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"epochs = 10: This line sets the number of epochs, which is the number of times the entire dataset will be passed forward and backward through the neural network during training.\n\ncallbacks: This is a list of callback functions that will be called during training. Two common callbacks are used here:\n\nModelCheckpoint: This callback saves the model's weights at different points during training. In this case, it will save the weights after each epoch in a file named \"save_at_{epoch}.keras\".\n\nEarlyStopping: This callback stops training when a monitored metric (in this case, validation loss) has stopped improving. The patience parameter defines the number of epochs with no improvement after which training will be stopped.\n\nmodel.compile(...): This line compiles the model, specifying the optimizer, loss function, and metrics to be used during training.\n\noptimizer=keras.optimizers.Adam(1e-3): The Adam optimizer is used with a learning rate of 1e-3 (0.001).\n\nloss=\"binary_crossentropy\": This is the loss function used for binary classification tasks.\n\nmetrics=[\"accuracy\"]: During training, accuracy will be monitored.\n\nhistory = model.fit(...): This line trains the model using the specified training data (train_generator) and validation data (test_generator). The training process is run for the specified number of epochs, and the specified callbacks are applied during training.\n\ntrain_generator: The generator for training data.\n\nepochs=epochs: The number of epochs to train the model.\n\ncallbacks=callbacks: The list of callbacks to be applied during training.\n\nvalidation_data=test_generator: The generator for validation data.\n\nThe training history, including metrics like loss and accuracy over epochs, is stored in the history variable. This information can be used for analysis and visualization.","metadata":{}},{"cell_type":"code","source":"epochs = 5\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"), keras.callbacks.EarlyStopping(patience=5)\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(\n    train_generator,\n    epochs=epochs,\n    callbacks=callbacks,\n    validation_data=test_generator,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:45:08.954657Z","iopub.execute_input":"2023-11-25T10:45:08.955378Z","iopub.status.idle":"2023-11-25T10:48:25.590656Z","shell.execute_reply.started":"2023-11-25T10:45:08.955344Z","shell.execute_reply":"2023-11-25T10:48:25.589249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreeze the base model\nbase_model.trainable = True\n\n# It's important to recompile your model after you make any changes\n# to the `trainable` attribute of any inner layer, so that your changes\n# are taken into account\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:59:29.638235Z","iopub.execute_input":"2023-11-25T11:59:29.640749Z","iopub.status.idle":"2023-11-25T11:59:29.692282Z","shell.execute_reply.started":"2023-11-25T11:59:29.640684Z","shell.execute_reply":"2023-11-25T11:59:29.690453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"), keras.callbacks.EarlyStopping(patience=5)\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-5),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(\n    train_generator,\n    epochs=epochs,\n    callbacks=callbacks,\n    validation_data=test_generator,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:00:34.137722Z","iopub.execute_input":"2023-11-25T12:00:34.138123Z","iopub.status.idle":"2023-11-25T12:12:23.235983Z","shell.execute_reply.started":"2023-11-25T12:00:34.138095Z","shell.execute_reply":"2023-11-25T12:12:23.233352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Test model","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:12:32.302878Z","iopub.execute_input":"2023-11-25T12:12:32.304385Z","iopub.status.idle":"2023-11-25T12:12:43.782049Z","shell.execute_reply.started":"2023-11-25T12:12:32.304335Z","shell.execute_reply":"2023-11-25T12:12:43.780210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualisation_of_results(generator):\n    \"\"\"\n    Images in batch should be 32 for correct visualisation of figures\n    \"\"\"\n    # Visualisation of datasets\n    features, target = next(generator)\n    # Get model predictions for batch\n    preds_proba = model.predict(features)\n    # Create a grid of images\n    fig, axes = plt.subplots(4, 8, figsize=(22, 11))\n\n    # Display each image in the grid\n    for i, ax in enumerate(axes.flatten()):\n        ax.imshow(features[i])\n        ax.set_title(f'Prediction: {np.round(preds_proba[i], 2)}')\n        ax.axis('off')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:12:48.114504Z","iopub.execute_input":"2023-11-25T12:12:48.115036Z","iopub.status.idle":"2023-11-25T12:12:48.123900Z","shell.execute_reply.started":"2023-11-25T12:12:48.114996Z","shell.execute_reply":"2023-11-25T12:12:48.122065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualisation_of_results(test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:12:49.454044Z","iopub.execute_input":"2023-11-25T12:12:49.454514Z","iopub.status.idle":"2023-11-25T12:12:58.069724Z","shell.execute_reply.started":"2023-11-25T12:12:49.454479Z","shell.execute_reply":"2023-11-25T12:12:58.067079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Even with frozen base model we reached accuracy on test model equal to 0.95. If we unfoze model, after training it on additional dataset we reach accuracy 0.975**","metadata":{}}]}